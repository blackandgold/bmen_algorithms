{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representations for Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array(42)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors (1D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([8,15,19,64])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices (2D tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[8,15,19,64],\n",
    "             [12,14,19,67]])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D tensors and higher-dimension tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[[8,15,19,64],\n",
    "               [2,17,20,1],\n",
    "               [12,14,19,67]],\n",
    "              [[8,15,19,64],\n",
    "               [2,17,20,1],\n",
    "               [12,14,19,67]]],)\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Attributes of Tensors\n",
    "* Number of axes (rank)\n",
    "* Shape (tuple of integers tat describes the dimeinsions)\n",
    "* Data type (dtype in Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions:  3\n",
      "Shape:  (60000, 28, 28)\n",
      "Type:  uint8\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_lables), (test_images,test_labels) = mnist.load_data()\n",
    "print('Dimensions: ',train_images.ndim)\n",
    "print('Shape: ',train_images.shape)\n",
    "print('Type: ',train_images.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "digit = train_images[9]\n",
    "plt.imshow(digit, cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating tensors in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90, 28, 28)\n",
      "(90, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "my_slice = train_images[10:100]\n",
    "print(my_slice.shape)\n",
    "my_slice = train_images[10:100,14:,14:] # select the lower left quadrant of data for images 10 to 100\n",
    "print(my_slice.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size of 128\n",
    "batch = train_images[:128] # batch 1\n",
    "batch = train_images[128:256]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Examples\n",
    "* Time series are 3D tensors of shape (samples, timesteps, features)\n",
    "* Images: 4D tensors of shape (samples, height, width, channels)\n",
    "* Video: 5D ensors of shape (samples, frames, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "(6, 1)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0.,1.],\n",
    "             [2.,3.],\n",
    "             [4.,5.]])\n",
    "print(x.shape)\n",
    "x = x.reshape((6,1))\n",
    "print(x.shape)\n",
    "x = x.reshape((3,2))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose (exchanging the rows and columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 300)\n"
     ]
    }
   ],
   "source": [
    "x = np.zeros((300,20))  # creates an array of all zerox of shape (300,20)\n",
    "x = np.transpose(x)\n",
    "print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
